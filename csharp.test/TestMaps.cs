using System;
using System.IO;
using System.Linq;
using NUnit.Framework;
using ParquetSharp.IO;
using ParquetSharp.Schema;

namespace ParquetSharp.Test
{
    [TestFixture]
    public class TestMaps
    {
        /// <summary>
        /// Test reading file generated by PyArrow, with generate_parquet.py
        /// </summary>
        [Test]
        public void CanReadMaps()
        {
            var directory = Path.GetDirectoryName(System.Reflection.Assembly.GetExecutingAssembly().Location);
            var path = Path.Combine(directory!, "TestFiles/map.parquet");

            using var fileReader = new ParquetFileReader(path);
            using var rowGroupReader = fileReader.RowGroup(0);

            using var col0Reader = rowGroupReader.Column(0).LogicalReader<string[]>();
            using var col1Reader = rowGroupReader.Column(1).LogicalReader<string[]>();
            using var col2Reader = rowGroupReader.Column(2).LogicalReader<string>();

            Assert.AreEqual(new[] {new[] {"key1", "key2"}, new[] {"key3", "key4"}}, col0Reader.ReadAll(2));
            Assert.AreEqual(new[] {new[] {"aaaa", "bbbb"}, new[] {"1111", "2222"}}, col1Reader.ReadAll(2));
            Assert.AreEqual(new[] {"foo", "bar"}, col2Reader.ReadAll(2));
        }

        [Test]
        public static void CanRoundtripOptionalMaps()
        {
            var keys = new[] {new[] {"k1", "k2"}, new[] {"k3", "k4"}, null, Array.Empty<string>()};
            var values = new[] {new[] {"v1", "v2"}, new[] {"v3", "v4"}, null, Array.Empty<string>()};

            DoRoundtripTest(true, keys!, values!);
        }

        [Test]
        public static void CanRoundtripRequiredMaps()
        {
            var keys = new[] {new[] {"k1", "k2"}, new[] {"k3", "k4"}, Array.Empty<string>()};
            var values = new[] {new[] {"v1", "v2"}, new[] {"v3", "v4"}, Array.Empty<string>()};

            DoRoundtripTest(false, keys, values);
        }

        [Test]
        public static void CanRoundtripNonStandardMapAnnotation()
        {
            var keys = new[] {new[] {"k1", "k2"}, new[] {"k3", "k4"}, Array.Empty<string>()};
            var values = new[] {new[] {"v1", "v2"}, new[] {"v3", "v4"}, Array.Empty<string>()};

            DoRoundtripTest(false, keys, values, CreateMapSchema(false, true));
        }

        /// <summary>
        /// This checks that values written to nested-nested required key field of 
        /// a nested-nested optional map can be read back.
        /// </summary>
        [Test]
        public static void TestNestedNestedOptionalMapWithRequiredKey()
        {
            const int rows = 5;
            const int nestedNestedElements = 111;
            const int maxNestedNestedIds = 200;
            const int randomSeed = 127;

            var inputNestedNestedKeys = new Nested<string[]?>[rows][];
            var inputNestedNestedValues = new Nested<string[]?>[rows][];

            Random r = new Random(randomSeed);
            for (int i = 0; i < rows; i++)
            {
                inputNestedNestedKeys[i] = new Nested<string[]?>[nestedNestedElements];
                inputNestedNestedValues[i] = new Nested<string[]?>[nestedNestedElements];

                for (int j = 0; j < nestedNestedElements; j++)
                {
                    string[]? vals = j % 2 == 0 ? Enumerable.Range(0, r.Next(maxNestedNestedIds)).Select(i => Guid.NewGuid().ToString()).ToArray() : null;

                    string[]? keys = j % 2 == 0 ? Enumerable.Range(0, vals!.Length).Select(i => Guid.NewGuid().ToString()).ToArray() : null;

                    inputNestedNestedKeys[i][j] = new Nested<string[]?>(keys);
                    inputNestedNestedValues[i][j] = new Nested<string[]?>(vals);
                }
            }

            using var buffer = new ResizableBuffer();
            using (var output = new BufferOutputStream(buffer))
            {
                using var nestedNestedKey = new PrimitiveNode("key", Repetition.Required, LogicalType.String(), PhysicalType.ByteArray);
                using var nestedNestedValue = new PrimitiveNode("value", Repetition.Required, LogicalType.String(), PhysicalType.ByteArray);
                using var nestedNestedMap = new GroupNode("key_value", Repetition.Repeated, new[] {nestedNestedKey, nestedNestedValue});
                using var nestedNestedStructure = new GroupNode("NestedNested", Repetition.Optional, new[] {nestedNestedMap}, LogicalType.Map());

                using var nestedElement = new GroupNode("element", Repetition.Required, new[] {nestedNestedStructure});
                using var nestedList = new GroupNode("list", Repetition.Repeated, new[] {nestedElement});
                using var nestedStructure = new GroupNode("Nested", Repetition.Required, new[] {nestedList}, LogicalType.List());

                using var schemaNode = new GroupNode("schema", Repetition.Required, new[] {nestedStructure});

                using var builder = new WriterPropertiesBuilder();
                using var writerProperties = builder.Build();
                using var fileWriter = new ParquetFileWriter(output, schemaNode, writerProperties);
                using var rowGroupWriter = fileWriter.AppendBufferedRowGroup();

                using var colWriter = rowGroupWriter.Column(0).LogicalWriter<Nested<string[]?>[]>();
                colWriter.WriteBatch(inputNestedNestedKeys);

                using var colWriter2 = rowGroupWriter.Column(1).LogicalWriter<Nested<string[]?>[]>();
                colWriter2.WriteBatch(inputNestedNestedValues);

                fileWriter.Close();
            }

            using var input = new BufferReader(buffer);
            using var fileReader = new ParquetFileReader(input);
            using var rowGroupReader = fileReader.RowGroup(0);

            using var colReader = rowGroupReader.Column(0).LogicalReader<string[]?[]>();
            var actualKeys = colReader.ReadAll((int) rowGroupReader.MetaData.NumRows);

            using var colReader2 = rowGroupReader.Column(1).LogicalReader<string[]?[]>();
            var actualValues = colReader2.ReadAll((int) rowGroupReader.MetaData.NumRows);

            Assert.IsNotEmpty(actualKeys);
            Assert.AreEqual(inputNestedNestedKeys.Length, actualKeys.Length);
            Assert.AreEqual(actualValues.Length, actualKeys.Length);

            for (var i = 0; i < inputNestedNestedKeys.Length; i++)
            {
                for (int j = 0; j < inputNestedNestedKeys[i].Length; j++)
                {
                    if (j % 2 == 0)
                    {
                        for (int k = 0; k < inputNestedNestedKeys[i][j].Value!.Length; k++)
                        {
                            Assert.AreEqual(inputNestedNestedKeys[i][j].Value![k], actualKeys[i][j]![k]);
                            Assert.AreEqual(inputNestedNestedValues[i][j].Value![k], actualValues[i][j]![k]);
                        }
                    }
                    else
                    {
                        Assert.IsNull(inputNestedNestedKeys[i][j].Value);
                        Assert.AreEqual(inputNestedNestedKeys[i][j].Value, actualKeys[i][j]);

                        Assert.IsNull(inputNestedNestedValues[i][j].Value);
                        Assert.AreEqual(inputNestedNestedValues[i][j].Value, actualValues[i][j]);
                    }
                }
            }

            fileReader.Close();
        }

        [Test]
        public static void NullsInRequiredMapGiveException()
        {
            var pool = MemoryPool.GetDefaultMemoryPool();
            Assert.AreEqual(0, pool.BytesAllocated);

            using (var buffer = new ResizableBuffer())
            {
                using var outStream = new BufferOutputStream(buffer);
                using var propertiesBuilder = new WriterPropertiesBuilder();
                using var writerProperties = propertiesBuilder.Build();
                using var schemaNode = CreateMapSchema(false);
                using var fileWriter = new ParquetFileWriter(outStream, schemaNode, writerProperties);
                using var rowGroupWriter = fileWriter.AppendRowGroup();
                using var colWriterKeys = rowGroupWriter.NextColumn().LogicalWriter<string[]>();

                var keys = new[] {new[] {"k1", "k2"}, new[] {"k3", "k4"}, null, Array.Empty<string>()};

                // Writing a column containing a null should throw an exception because the schema says values are required
                var exception = Assert.Throws<InvalidOperationException>(() => colWriterKeys.WriteBatch(keys!))!;
                Assert.AreEqual("Cannot write a null array value for a required array column", exception.Message);

                // We will also get an exception because we haven't written any data
                var closeException = Assert.Throws<ParquetException>(() => fileWriter.Close())!;
                Assert.IsTrue(closeException.Message.Contains("Only 0 out of 2 columns are initialized"));
            }

            Assert.AreEqual(0, pool.BytesAllocated);
        }

        private static void DoRoundtripTest(bool optional, string[][] keys, string[][] values, GroupNode? schemaNode = null)
        {
            var pool = MemoryPool.GetDefaultMemoryPool();
            Assert.AreEqual(0, pool.BytesAllocated);

            using (var buffer = new ResizableBuffer())
            {
                using (var outStream = new BufferOutputStream(buffer))
                {
                    using var propertiesBuilder = new WriterPropertiesBuilder();
                    using var writerProperties = propertiesBuilder.Build();
                    schemaNode ??= CreateMapSchema(optional);
                    using var fileWriter = new ParquetFileWriter(outStream, schemaNode, writerProperties);
                    using var rowGroupWriter = fileWriter.AppendRowGroup();

                    using var colWriterKeys = rowGroupWriter.NextColumn().LogicalWriter<string[]>();
                    colWriterKeys.WriteBatch(keys);

                    using var colWriterValues = rowGroupWriter.NextColumn().LogicalWriter<string[]>();
                    colWriterValues.WriteBatch(values);

                    fileWriter.Close();
                }

                // Read it back.
                using var inStream = new BufferReader(buffer);
                using var fileReader = new ParquetFileReader(inStream);
                using var rowGroup = fileReader.RowGroup(0);

                using var keysColReader = rowGroup.Column(0).LogicalReader<string[]>();
                var keysActual = keysColReader.ReadAll(values.Length);
                using var valuesColReader = rowGroup.Column(1).LogicalReader<string[]>();
                var valuesActual = valuesColReader.ReadAll(values.Length);

                Assert.AreEqual(keys, keysActual);
                Assert.AreEqual(values, valuesActual);
            }

            Assert.AreEqual(0, pool.BytesAllocated);
        }

        private static GroupNode CreateMapSchema(bool optional, bool extraLogicalMapType = false)
        {
            using var stringType = LogicalType.String();
            using var mapType = LogicalType.Map();

            using var keyNode = new PrimitiveNode("key", Repetition.Required, stringType, PhysicalType.ByteArray);
            using var valueNode = new PrimitiveNode("value", Repetition.Optional, stringType, PhysicalType.ByteArray);
            using var keyValueNode = new GroupNode(
                "key_value", Repetition.Repeated, new Node[] {keyNode, valueNode}, extraLogicalMapType ? mapType : null);
            var repetition = optional ? Repetition.Optional : Repetition.Required;
            using var colNode = new GroupNode(
                "col1", repetition, new Node[] {keyValueNode}, mapType);

            return new GroupNode(
                "schema", Repetition.Required, new Node[] {colNode});
        }
    }
}
